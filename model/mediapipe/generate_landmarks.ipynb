{
 "cells": [
  {
   "cell_type": "code",
   "id": "404a6e02806f8447",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T11:54:49.583078Z",
     "start_time": "2025-06-13T11:54:49.580576Z"
    }
   },
   "source": [
    "# STEP 1: Import the necessary modules.\n",
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.tasks.python.vision import RunningMode"
   ],
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T12:34:49.522086Z",
     "start_time": "2025-06-13T12:34:49.503703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# STEP 2: Setup HandLandmarker configuration\n",
    "base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
    "options = vision.HandLandmarkerOptions(base_options=base_options,\n",
    "                                       num_hands=2, running_mode=RunningMode.VIDEO)"
   ],
   "id": "9935f3800d0a264b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1749818089.506500 55382079 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Max\n",
      "W0000 00:00:1749818089.512549 55534899 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1749818089.518071 55534899 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-13T13:29:50.469936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# STEP 4: Generate landmarks for each frame of every video\n",
    "for root, _, files in os.walk(\"../food/data\"):\n",
    "    for filename in files:  # loop through files in the current directory\n",
    "        capture = cv2.VideoCapture(os.path.join(root, filename))\n",
    "        detector = vision.HandLandmarker.create_from_options(options)\n",
    "        detection_results = []\n",
    "        frameNr = 0\n",
    "        while True:\n",
    "            ret, frame = capture.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            # Convert the frame to a MediaPipe Image.\n",
    "            image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "            # Detect hand landmarks in the current frame.\n",
    "            detection_result = detector.detect_for_video(image, frameNr)\n",
    "            csv = []\n",
    "\n",
    "            # Collect landmarks and handedness for each detected hand.\n",
    "            for idx in range(len(detection_result.hand_landmarks)):\n",
    "                handedness = detection_result.handedness[idx][0].category_name\n",
    "                landmarks = detection_result.hand_landmarks[idx]\n",
    "                csv.append(\"\\n\".join(map(lambda x: f\"{handedness}, x:{x.x}, y:{x.y}, z:{x.z}\", landmarks)))\n",
    "\n",
    "            # Write the landmarks to a CSV file.\n",
    "            try:\n",
    "                os.mkdir(os.path.join(root, \"landmarks\"))\n",
    "            except FileExistsError:\n",
    "                pass\n",
    "            with open(os.path.join(root, f\"landmarks/{filename}_landmarks.csv\"), \"a\") as f:\n",
    "                f.write(f\"frame {frameNr} \\n\")\n",
    "                f.write(\"\\n\".join(csv))\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "            frameNr = frameNr + 1\n",
    "            print(f\"Processed {filename} frame {frameNr}\")\n",
    "        capture.release()"
   ],
   "id": "9b64ed4a3c6a6ff9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"../food/data/.DS_Store\"\n",
      "I0000 00:00:1749821390.480751 55382079 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Max\n",
      "W0000 00:00:1749821390.487599 55646925 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1749821390.492400 55646929 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1749821390.503282 55382079 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Max\n",
      "W0000 00:00:1749821390.509363 55646952 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1749821390.514205 55646952 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed apfel_test_1.mp4 frame 1\n",
      "Processed apfel_test_1.mp4 frame 2\n",
      "Processed apfel_test_1.mp4 frame 3\n",
      "Processed apfel_test_1.mp4 frame 4\n",
      "Processed apfel_test_1.mp4 frame 5\n",
      "Processed apfel_test_1.mp4 frame 6\n",
      "Processed apfel_test_1.mp4 frame 7\n",
      "Processed apfel_test_1.mp4 frame 8\n",
      "Processed apfel_test_1.mp4 frame 9\n",
      "Processed apfel_test_1.mp4 frame 10\n",
      "Processed apfel_test_1.mp4 frame 11\n",
      "Processed apfel_test_1.mp4 frame 12\n",
      "Processed apfel_test_1.mp4 frame 13\n",
      "Processed apfel_test_1.mp4 frame 14\n",
      "Processed apfel_test_1.mp4 frame 15\n",
      "Processed apfel_test_1.mp4 frame 16\n",
      "Processed apfel_test_1.mp4 frame 17\n",
      "Processed apfel_test_1.mp4 frame 18\n",
      "Processed apfel_test_1.mp4 frame 19\n",
      "Processed apfel_test_1.mp4 frame 20\n",
      "Processed apfel_test_1.mp4 frame 21\n",
      "Processed apfel_test_1.mp4 frame 22\n",
      "Processed apfel_test_1.mp4 frame 23\n",
      "Processed apfel_test_1.mp4 frame 24\n",
      "Processed apfel_test_1.mp4 frame 25\n",
      "Processed apfel_test_1.mp4 frame 26\n",
      "Processed apfel_test_1.mp4 frame 27\n",
      "Processed apfel_test_1.mp4 frame 28\n",
      "Processed apfel_test_1.mp4 frame 29\n",
      "Processed apfel_test_1.mp4 frame 30\n",
      "Processed apfel_test_1.mp4 frame 31\n",
      "Processed apfel_test_1.mp4 frame 32\n",
      "Processed apfel_test_1.mp4 frame 33\n",
      "Processed apfel_test_1.mp4 frame 34\n",
      "Processed apfel_test_1.mp4 frame 35\n",
      "Processed apfel_test_1.mp4 frame 36\n",
      "Processed apfel_test_1.mp4 frame 37\n",
      "Processed apfel_test_1.mp4 frame 38\n",
      "Processed apfel_test_1.mp4 frame 39\n",
      "Processed apfel_test_1.mp4 frame 40\n",
      "Processed apfel_test_1.mp4 frame 41\n",
      "Processed apfel_test_1.mp4 frame 42\n",
      "Processed apfel_test_1.mp4 frame 43\n",
      "Processed apfel_test_1.mp4 frame 44\n",
      "Processed apfel_test_1.mp4 frame 45\n",
      "Processed apfel_test_1.mp4 frame 46\n",
      "Processed apfel_test_1.mp4 frame 47\n",
      "Processed apfel_test_1.mp4 frame 48\n",
      "Processed apfel_test_1.mp4 frame 49\n",
      "Processed apfel_test_1.mp4 frame 50\n",
      "Processed apfel_test_1.mp4 frame 51\n",
      "Processed apfel_test_1.mp4 frame 52\n",
      "Processed apfel_test_1.mp4 frame 53\n",
      "Processed apfel_test_1.mp4 frame 54\n",
      "Processed apfel_test_1.mp4 frame 55\n",
      "Processed apfel_test_1.mp4 frame 56\n",
      "Processed apfel_test_1.mp4 frame 57\n",
      "Processed apfel_test_1.mp4 frame 58\n",
      "Processed apfel_test_1.mp4 frame 59\n",
      "Processed apfel_test_1.mp4 frame 60\n",
      "Processed apfel_test_1.mp4 frame 61\n",
      "Processed apfel_test_1.mp4 frame 62\n",
      "Processed apfel_test_1.mp4 frame 63\n",
      "Processed apfel_test_1.mp4 frame 64\n",
      "Processed apfel_test_1.mp4 frame 65\n",
      "Processed apfel_test_1.mp4 frame 66\n",
      "Processed apfel_test_1.mp4 frame 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1749821392.519693 55382079 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Max\n",
      "W0000 00:00:1749821392.525127 55647060 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1749821392.529513 55647068 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed apfel_test_0.mp4 frame 1\n",
      "Processed apfel_test_0.mp4 frame 2\n",
      "Processed apfel_test_0.mp4 frame 3\n",
      "Processed apfel_test_0.mp4 frame 4\n",
      "Processed apfel_test_0.mp4 frame 5\n",
      "Processed apfel_test_0.mp4 frame 6\n",
      "Processed apfel_test_0.mp4 frame 7\n",
      "Processed apfel_test_0.mp4 frame 8\n",
      "Processed apfel_test_0.mp4 frame 9\n",
      "Processed apfel_test_0.mp4 frame 10\n",
      "Processed apfel_test_0.mp4 frame 11\n",
      "Processed apfel_test_0.mp4 frame 12\n",
      "Processed apfel_test_0.mp4 frame 13\n",
      "Processed apfel_test_0.mp4 frame 14\n",
      "Processed apfel_test_0.mp4 frame 15\n",
      "Processed apfel_test_0.mp4 frame 16\n",
      "Processed apfel_test_0.mp4 frame 17\n",
      "Processed apfel_test_0.mp4 frame 18\n",
      "Processed apfel_test_0.mp4 frame 19\n",
      "Processed apfel_test_0.mp4 frame 20\n",
      "Processed apfel_test_0.mp4 frame 21\n",
      "Processed apfel_test_0.mp4 frame 22\n",
      "Processed apfel_test_0.mp4 frame 23\n",
      "Processed apfel_test_0.mp4 frame 24\n",
      "Processed apfel_test_0.mp4 frame 25\n",
      "Processed apfel_test_0.mp4 frame 26\n",
      "Processed apfel_test_0.mp4 frame 27\n",
      "Processed apfel_test_0.mp4 frame 28\n",
      "Processed apfel_test_0.mp4 frame 29\n",
      "Processed apfel_test_0.mp4 frame 30\n",
      "Processed apfel_test_0.mp4 frame 31\n",
      "Processed apfel_test_0.mp4 frame 32\n",
      "Processed apfel_test_0.mp4 frame 33\n",
      "Processed apfel_test_0.mp4 frame 34\n",
      "Processed apfel_test_0.mp4 frame 35\n",
      "Processed apfel_test_0.mp4 frame 36\n",
      "Processed apfel_test_0.mp4 frame 37\n",
      "Processed apfel_test_0.mp4 frame 38\n",
      "Processed apfel_test_0.mp4 frame 39\n",
      "Processed apfel_test_0.mp4 frame 40\n",
      "Processed apfel_test_0.mp4 frame 41\n",
      "Processed apfel_test_0.mp4 frame 42\n",
      "Processed apfel_test_0.mp4 frame 43\n",
      "Processed apfel_test_0.mp4 frame 44\n",
      "Processed apfel_test_0.mp4 frame 45\n",
      "Processed apfel_test_0.mp4 frame 46\n",
      "Processed apfel_test_0.mp4 frame 47\n",
      "Processed apfel_test_0.mp4 frame 48\n",
      "Processed apfel_test_0.mp4 frame 49\n",
      "Processed apfel_test_0.mp4 frame 50\n",
      "Processed apfel_test_0.mp4 frame 51\n",
      "Processed apfel_test_0.mp4 frame 52\n",
      "Processed apfel_test_0.mp4 frame 53\n",
      "Processed apfel_test_0.mp4 frame 54\n",
      "Processed apfel_test_0.mp4 frame 55\n",
      "Processed apfel_test_0.mp4 frame 56\n",
      "Processed apfel_test_0.mp4 frame 57\n",
      "Processed kiwi_test_1.mp4 frame 1\n",
      "Processed kiwi_test_1.mp4 frame 2\n",
      "Processed kiwi_test_1.mp4 frame 3\n",
      "Processed kiwi_test_1.mp4 frame 4\n",
      "Processed kiwi_test_1.mp4 frame 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: Couldn't read video stream from file \"../food/data/test/apfel/landmarks/apfel_test_1.mp4_landmarks.csv\"\n",
      "I0000 00:00:1749821393.242454 55382079 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Max\n",
      "W0000 00:00:1749821393.247780 55647092 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1749821393.251624 55647092 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "OpenCV: Couldn't read video stream from file \"../food/data/test/apfel/landmarks/apfel_test_0.mp4_landmarks.csv\"\n",
      "I0000 00:00:1749821393.258619 55382079 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Max\n",
      "W0000 00:00:1749821393.264307 55647107 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1749821393.268261 55647107 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1749821393.274481 55382079 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Max\n",
      "W0000 00:00:1749821393.279914 55647136 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1749821393.283675 55647136 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed kiwi_test_1.mp4 frame 6\n",
      "Processed kiwi_test_1.mp4 frame 7\n",
      "Processed kiwi_test_1.mp4 frame 8\n",
      "Processed kiwi_test_1.mp4 frame 9\n",
      "Processed kiwi_test_1.mp4 frame 10\n",
      "Processed kiwi_test_1.mp4 frame 11\n",
      "Processed kiwi_test_1.mp4 frame 12\n",
      "Processed kiwi_test_1.mp4 frame 13\n",
      "Processed kiwi_test_1.mp4 frame 14\n",
      "Processed kiwi_test_1.mp4 frame 15\n",
      "Processed kiwi_test_1.mp4 frame 16\n",
      "Processed kiwi_test_1.mp4 frame 17\n",
      "Processed kiwi_test_1.mp4 frame 18\n",
      "Processed kiwi_test_1.mp4 frame 19\n",
      "Processed kiwi_test_1.mp4 frame 20\n",
      "Processed kiwi_test_1.mp4 frame 21\n",
      "Processed kiwi_test_1.mp4 frame 22\n",
      "Processed kiwi_test_1.mp4 frame 23\n",
      "Processed kiwi_test_1.mp4 frame 24\n",
      "Processed kiwi_test_1.mp4 frame 25\n",
      "Processed kiwi_test_1.mp4 frame 26\n",
      "Processed kiwi_test_1.mp4 frame 27\n",
      "Processed kiwi_test_1.mp4 frame 28\n",
      "Processed kiwi_test_1.mp4 frame 29\n",
      "Processed kiwi_test_1.mp4 frame 30\n",
      "Processed kiwi_test_1.mp4 frame 31\n",
      "Processed kiwi_test_1.mp4 frame 32\n",
      "Processed kiwi_test_1.mp4 frame 33\n",
      "Processed kiwi_test_1.mp4 frame 34\n",
      "Processed kiwi_test_1.mp4 frame 35\n",
      "Processed kiwi_test_1.mp4 frame 36\n",
      "Processed kiwi_test_1.mp4 frame 37\n",
      "Processed kiwi_test_1.mp4 frame 38\n",
      "Processed kiwi_test_1.mp4 frame 39\n",
      "Processed kiwi_test_1.mp4 frame 40\n",
      "Processed kiwi_test_1.mp4 frame 41\n",
      "Processed kiwi_test_1.mp4 frame 42\n",
      "Processed kiwi_test_1.mp4 frame 43\n",
      "Processed kiwi_test_1.mp4 frame 44\n",
      "Processed kiwi_test_1.mp4 frame 45\n",
      "Processed kiwi_test_1.mp4 frame 46\n",
      "Processed kiwi_test_1.mp4 frame 47\n",
      "Processed kiwi_test_1.mp4 frame 48\n",
      "Processed kiwi_test_1.mp4 frame 49\n",
      "Processed kiwi_test_1.mp4 frame 50\n",
      "Processed kiwi_test_1.mp4 frame 51\n",
      "Processed kiwi_test_1.mp4 frame 52\n",
      "Processed kiwi_test_1.mp4 frame 53\n",
      "Processed kiwi_test_1.mp4 frame 54\n",
      "Processed kiwi_test_1.mp4 frame 55\n",
      "Processed kiwi_test_1.mp4 frame 56\n",
      "Processed kiwi_test_1.mp4 frame 57\n",
      "Processed kiwi_test_1.mp4 frame 58\n",
      "Processed kiwi_test_1.mp4 frame 59\n",
      "Processed kiwi_test_1.mp4 frame 60\n",
      "Processed kiwi_test_1.mp4 frame 61\n",
      "Processed kiwi_test_1.mp4 frame 62\n",
      "Processed kiwi_test_1.mp4 frame 63\n",
      "Processed kiwi_test_1.mp4 frame 64\n",
      "Processed kiwi_test_1.mp4 frame 65\n",
      "Processed kiwi_test_1.mp4 frame 66\n",
      "Processed kiwi_test_1.mp4 frame 67\n",
      "Processed kiwi_test_1.mp4 frame 68\n",
      "Processed kiwi_test_1.mp4 frame 69\n",
      "Processed kiwi_test_1.mp4 frame 70\n",
      "Processed kiwi_test_1.mp4 frame 71\n",
      "Processed kiwi_test_1.mp4 frame 72\n",
      "Processed kiwi_test_1.mp4 frame 73\n",
      "Processed kiwi_test_1.mp4 frame 74\n",
      "Processed kiwi_test_1.mp4 frame 75\n",
      "Processed kiwi_test_1.mp4 frame 76\n",
      "Processed kiwi_test_1.mp4 frame 77\n",
      "Processed kiwi_test_1.mp4 frame 78\n",
      "Processed kiwi_test_1.mp4 frame 79\n",
      "Processed kiwi_test_1.mp4 frame 80\n",
      "Processed kiwi_test_0.mp4 frame 1\n",
      "Processed kiwi_test_0.mp4 frame 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1749821394.341393 55382079 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Max\n",
      "W0000 00:00:1749821394.346321 55647189 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1749821394.350374 55647194 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed kiwi_test_0.mp4 frame 3\n",
      "Processed kiwi_test_0.mp4 frame 4\n",
      "Processed kiwi_test_0.mp4 frame 5\n",
      "Processed kiwi_test_0.mp4 frame 6\n",
      "Processed kiwi_test_0.mp4 frame 7\n",
      "Processed kiwi_test_0.mp4 frame 8\n",
      "Processed kiwi_test_0.mp4 frame 9\n",
      "Processed kiwi_test_0.mp4 frame 10\n",
      "Processed kiwi_test_0.mp4 frame 11\n",
      "Processed kiwi_test_0.mp4 frame 12\n",
      "Processed kiwi_test_0.mp4 frame 13\n",
      "Processed kiwi_test_0.mp4 frame 14\n",
      "Processed kiwi_test_0.mp4 frame 15\n",
      "Processed kiwi_test_0.mp4 frame 16\n",
      "Processed kiwi_test_0.mp4 frame 17\n",
      "Processed kiwi_test_0.mp4 frame 18\n",
      "Processed kiwi_test_0.mp4 frame 19\n",
      "Processed kiwi_test_0.mp4 frame 20\n",
      "Processed kiwi_test_0.mp4 frame 21\n",
      "Processed kiwi_test_0.mp4 frame 22\n",
      "Processed kiwi_test_0.mp4 frame 23\n",
      "Processed kiwi_test_0.mp4 frame 24\n",
      "Processed kiwi_test_0.mp4 frame 25\n",
      "Processed kiwi_test_0.mp4 frame 26\n",
      "Processed kiwi_test_0.mp4 frame 27\n",
      "Processed kiwi_test_0.mp4 frame 28\n",
      "Processed kiwi_test_0.mp4 frame 29\n",
      "Processed kiwi_test_0.mp4 frame 30\n",
      "Processed kiwi_test_0.mp4 frame 31\n",
      "Processed kiwi_test_0.mp4 frame 32\n",
      "Processed kiwi_test_0.mp4 frame 33\n",
      "Processed kiwi_test_0.mp4 frame 34\n",
      "Processed kiwi_test_0.mp4 frame 35\n",
      "Processed kiwi_test_0.mp4 frame 36\n",
      "Processed kiwi_test_0.mp4 frame 37\n",
      "Processed kiwi_test_0.mp4 frame 38\n",
      "Processed kiwi_test_0.mp4 frame 39\n",
      "Processed kiwi_test_0.mp4 frame 40\n",
      "Processed kiwi_test_0.mp4 frame 41\n",
      "Processed kiwi_test_0.mp4 frame 42\n",
      "Processed banane_test_1.mp4 frame 1\n",
      "Processed banane_test_1.mp4 frame 2\n",
      "Processed banane_test_1.mp4 frame 3\n",
      "Processed banane_test_1.mp4 frame 4\n",
      "Processed banane_test_1.mp4 frame 5\n",
      "Processed banane_test_1.mp4 frame 6\n",
      "Processed banane_test_1.mp4 frame 7\n",
      "Processed banane_test_1.mp4 frame 8\n",
      "Processed banane_test_1.mp4 frame 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1749821394.868818 55382079 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3 Max\n",
      "W0000 00:00:1749821394.874102 55647229 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1749821394.881285 55647239 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed banane_test_1.mp4 frame 10\n",
      "Processed banane_test_1.mp4 frame 11\n",
      "Processed banane_test_1.mp4 frame 12\n",
      "Processed banane_test_1.mp4 frame 13\n",
      "Processed banane_test_1.mp4 frame 14\n",
      "Processed banane_test_1.mp4 frame 15\n",
      "Processed banane_test_1.mp4 frame 16\n",
      "Processed banane_test_1.mp4 frame 17\n",
      "Processed banane_test_1.mp4 frame 18\n",
      "Processed banane_test_1.mp4 frame 19\n",
      "Processed banane_test_1.mp4 frame 20\n",
      "Processed banane_test_1.mp4 frame 21\n",
      "Processed banane_test_1.mp4 frame 22\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
